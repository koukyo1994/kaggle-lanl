{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "pd.options.display.precision = 15\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import datetime\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from scipy import linalg\n",
    "#from scipy import signal\n",
    "from scipy.signal import sosfilt\n",
    "from scipy.signal import butter\n",
    "import pywt\n",
    "from tsfresh.feature_extraction import feature_calculators\n",
    "\n",
    "import gc\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from scipy.signal import hilbert\n",
    "from scipy.signal import hann\n",
    "from scipy.signal import convolve\n",
    "from scipy import stats\n",
    "from sklearn.kernel_ridge import KernelRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainer.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataPath = Path('../data/train_wave_split')\n",
    "delimiter = ','\n",
    "\n",
    "rows = 150_000\n",
    "n_samples = 150_000\n",
    "sample_duration = 0.02\n",
    "sample_rate = n_samples * (1 / sample_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maddest(d, axis=None):\n",
    "    return np.mean(np.absolute(d - np.mean(d, axis)), axis)\n",
    "\n",
    "def high_pass_filter(x, low_cutoff=1000, sample_rate=sample_rate):\n",
    "    nyquist = 0.5 * sample_rate\n",
    "    norm_low_cutoff = low_cutoff / nyquist\n",
    "    sos = butter(10, Wn=[norm_low_cutoff], btype='highpass', output='sos')\n",
    "    filtered_sig = sosfilt(sos, x)\n",
    "\n",
    "    return filtered_sig\n",
    "\n",
    "def denoise_signal(x, wavelet='db4', level=1):\n",
    "    coeff = pywt.wavedec( x, wavelet, mode=\"per\" )\n",
    "    sigma = (1/0.6745) * maddest( coeff[-level] )\n",
    "    uthresh = sigma * np.sqrt( 2*np.log( len( x ) ) )\n",
    "    coeff[1:] = ( pywt.threshold( i, value=uthresh, mode='hard' ) for i in coeff[1:] )\n",
    "\n",
    "    return pywt.waverec( coeff, wavelet, mode='per' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_trend_feature(arr, abs_values=False):\n",
    "    idx = np.array(range(len(arr)))\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(idx.reshape(-1, 1), arr)\n",
    "    return lr.coef_[0]\n",
    "\n",
    "def classic_sta_lta(x, length_sta, length_lta):\n",
    "    \n",
    "    sta = np.cumsum(x ** 2)\n",
    "\n",
    "    # Convert to float\n",
    "    sta = np.require(sta, dtype=np.float)\n",
    "\n",
    "    # Copy for LTA\n",
    "    lta = sta.copy()\n",
    "\n",
    "    # Compute the STA and the LTA\n",
    "    sta[length_sta:] = sta[length_sta:] - sta[:-length_sta]\n",
    "    sta /= length_sta\n",
    "    lta[length_lta:] = lta[length_lta:] - lta[:-length_lta]\n",
    "    lta /= length_lta\n",
    "\n",
    "    # Pad zeros\n",
    "    sta[:length_lta - 1] = 0\n",
    "\n",
    "    # Avoid division by zero by setting zero values to tiny float\n",
    "    dtiny = np.finfo(0.0).tiny\n",
    "    idx = lta < dtiny\n",
    "    lta[idx] = dtiny\n",
    "\n",
    "    return sta / lta\n",
    "\n",
    "def calc_change_rate(x):\n",
    "    change = (np.diff(x) / x[:-1]).values\n",
    "    change = change[np.nonzero(change)[0]]\n",
    "    change = change[~np.isnan(change)]\n",
    "    change = change[change != -np.inf]\n",
    "    change = change[change != np.inf]\n",
    "    return np.mean(change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(x):\n",
    "    x =  pd.Series(x)\n",
    "    x_abs = np.abs(x)\n",
    "    x_max = x.max()\n",
    "    x_min = x.min()\n",
    "    \n",
    "    X_features = pd.Series(dtype=np.float64)\n",
    "    \n",
    "    X_features.loc['mean'] = x.mean()\n",
    "    X_features.loc['std'] = x.std()\n",
    "    X_features.loc['max'] = x_max\n",
    "    X_features.loc['min'] = x_min\n",
    "    X_features.loc['mad'] = x.mad()\n",
    "    X_features.loc['kurt'] = x.kurtosis()\n",
    "    X_features.loc['skew'] = x.skew()\n",
    "    #X_features.loc['med'] = x.median()\n",
    "    \n",
    "    X_features.loc['max_to_min'] = x_max / np.abs(x_min)\n",
    "    X_features.loc['max_to_min_diff'] = x_max - np.abs(x_min)\n",
    "    X_features.loc['max_min_diff'] = x_max - x_min\n",
    "    X_features.loc['count_big'] = len(x[x_abs > 1000])\n",
    "    \n",
    "    X_features.loc['mean_change_abs'] = np.mean(np.diff(x))\n",
    "    X_features.loc['mean_change_rate'] = calc_change_rate(x)\n",
    "    X_features.loc['abs_max'] = x_abs.max()\n",
    "    #X_features.loc['abs_min'] = x_abs.min()\n",
    "    X_features.loc['abs_mean'] = x_abs.mean()\n",
    "    X_features.loc['abs_std'] = x_abs.std()\n",
    "\n",
    "\n",
    "    X_features.loc['mean_change_rate_first_50000'] = calc_change_rate(x[:50000])\n",
    "    X_features.loc['mean_change_rate_last_50000'] = calc_change_rate(x[-50000:])\n",
    "    X_features.loc['mean_change_rate_first_10000'] = calc_change_rate(x[:10000])\n",
    "    X_features.loc['mean_change_rate_last_10000'] = calc_change_rate(x[-10000:])\n",
    "    \n",
    "    X_features.loc['q999'] = np.quantile(x,0.999)\n",
    "    X_features.loc['q99'] = np.quantile(x, 0.99)\n",
    "    X_features.loc['q95'] = np.quantile(x, 0.95)\n",
    "    X_features.loc['q05'] = np.quantile(x, 0.05)\n",
    "    X_features.loc['q01'] = np.quantile(x, 0.01)\n",
    "    X_features.loc['q001'] = np.quantile(x,0.001)\n",
    "    \n",
    "#     X_features.loc['abs_q95'] = np.quantile(x_abs, 0.95)\n",
    "#     X_features.loc['abs_q99'] = np.quantile(x_abs, 0.99)\n",
    "#     X_features.loc['abs_q05'] = np.quantile(x_abs, 0.05)\n",
    "#     X_features.loc['abs_q01'] = np.quantile(x_abs, 0.01)\n",
    "    \n",
    "    X_features.loc['trend'] = add_trend_feature(x)\n",
    "    X_features.loc['abs_trend'] = add_trend_feature(x_abs)\n",
    "        \n",
    "#     X_features.loc['Hilbert_mean'] = np.abs(hilbert(x)).mean()\n",
    "    X_features.loc['Hann_window_mean'] = (convolve(x, hann(150), mode='same') / sum(hann(150))).mean()\n",
    "    X_features.loc['classic_sta_lta1_mean'] = classic_sta_lta(x, 500, 10000).mean()\n",
    "    X_features.loc['classic_sta_lta2_mean'] = classic_sta_lta(x, 5000, 100000).mean()\n",
    "    X_features.loc['classic_sta_lta3_mean'] = classic_sta_lta(x, 3333, 6666).mean()\n",
    "    X_features.loc['classic_sta_lta4_mean'] = classic_sta_lta(x, 10000, 25000).mean()\n",
    "    X_features.loc['classic_sta_lta5_mean'] = classic_sta_lta(x, 50, 1000).mean()\n",
    "    X_features.loc['classic_sta_lta6_mean'] = classic_sta_lta(x, 100, 5000).mean()\n",
    "    X_features.loc['classic_sta_lta7_mean'] = classic_sta_lta(x, 333, 666).mean()\n",
    "    X_features.loc['classic_sta_lta8_mean'] = classic_sta_lta(x, 4000, 10000).mean()\n",
    "    \n",
    "#     no_of_std = 3\n",
    "#     X_features.loc['Moving_average_700_mean'] = x.rolling(window=700).mean().mean(skipna=True)\n",
    "#     X_features.loc['MA_700MA_std_mean'] = x.rolling(window=700).std().mean()\n",
    "#     X_features.loc['MA_700MA_BB_highf_mean'] = (X_features.loc['Moving_average_700_mean'] + no_of_std * X_features.loc['MA_700MA_std_mean']).mean()\n",
    "#     X_features.loc['MA_700MA_BB_low_mean'] = (X_features.loc['Moving_average_700_mean'] - no_of_std * X_features.loc['MA_700MA_std_mean']).mean()\n",
    "#     X_features.loc['MA_400MA_std_mean'] = x.rolling(window=400).std().mean()\n",
    "#     X_features.loc['MA_400MA_BB_high_mean'] = (X_features.loc['Moving_average_700_mean'] + no_of_std * X_features.loc['MA_400MA_std_mean']).mean()\n",
    "#     X_features.loc['MA_400MA_BB_low_mean'] = (X_features.loc['Moving_average_700_mean'] - no_of_std * X_features.loc['MA_400MA_std_mean']).mean()\n",
    "#     X_features.loc['MA_1000MA_std_mean'] = x.rolling(window=1000).std().mean()\n",
    "#     X_features.drop('Moving_average_700_mean', inplace=True)\n",
    "    \n",
    "    X_features.loc['iqr'] = np.subtract(*np.percentile(x, [75, 25]))\n",
    "    X_features.loc['ave10'] = stats.trim_mean(x, 0.1)\n",
    "\n",
    "    X_features.loc[f'num_peaks_10'] = feature_calculators.number_peaks(x, 10)\n",
    "    X_features.loc[f'c3_100'] = feature_calculators.c3(x, 100)\n",
    "    X_features.loc[f'autocorrelation_5'] = feature_calculators.autocorrelation(x, 5)\n",
    "\n",
    "    for windows in [10, 100, 1000]:\n",
    "        x_roll_std = x.rolling(windows).std().dropna().values\n",
    "        x_roll_mean = x.rolling(windows).mean().dropna().values\n",
    "        \n",
    "        X_features.loc['ave_roll_std_' + str(windows)] = x_roll_std.mean()\n",
    "        X_features.loc['std_roll_std_' + str(windows)] = x_roll_std.std()\n",
    "        X_features.loc['max_roll_std_' + str(windows)] = x_roll_std.max()\n",
    "        X_features.loc['min_roll_std_' + str(windows)] = x_roll_std.min()\n",
    "        X_features.loc['q01_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.01)\n",
    "        X_features.loc['q05_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.05)\n",
    "        X_features.loc['q95_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.95)\n",
    "        X_features.loc['q99_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.99)\n",
    "        X_features.loc['av_change_abs_roll_std_' + str(windows)] = np.mean(np.diff(x_roll_std))\n",
    "        X_features.loc['av_change_rate_roll_std_' + str(windows)] = np.mean(np.nonzero((np.diff(x_roll_std) / x_roll_std[:-1]))[0])\n",
    "        #X_features.loc['abs_max_roll_std_' + str(windows)] = np.abs(x_roll_std).max()\n",
    "        \n",
    "        X_features.loc['ave_roll_mean_' + str(windows)] = x_roll_mean.mean()\n",
    "        X_features.loc['std_roll_mean_' + str(windows)] = x_roll_mean.std()\n",
    "        X_features.loc['max_roll_mean_' + str(windows)] = x_roll_mean.max()\n",
    "        X_features.loc['min_roll_mean_' + str(windows)] = x_roll_mean.min()\n",
    "        X_features.loc['q01_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.01)\n",
    "        X_features.loc['q05_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.05)\n",
    "        X_features.loc['q95_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.95)\n",
    "        X_features.loc['q99_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.99)\n",
    "        X_features.loc['av_change_abs_roll_mean_' + str(windows)] = np.mean(np.diff(x_roll_mean))\n",
    "        X_features.loc['av_change_rate_roll_mean_' + str(windows)] = np.mean(np.nonzero((np.diff(x_roll_mean) / x_roll_mean[:-1]))[0])\n",
    "        X_features.loc['abs_max_roll_mean_' + str(windows)] = np.abs(x_roll_mean).max()\n",
    "        \n",
    "    return X_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(slide=150_000, window=10_000, val_eq_nums=[1,15,16]):\n",
    "    train = []\n",
    "    val = []\n",
    "\n",
    "    for eq_num in tqdm(range(17)):\n",
    "        data = pd.read_csv(DataPath/'train_wave_{}.csv'.format(eq_num))\n",
    "        acoustic_data = data['acoustic_data'].values\n",
    "        time_data = data['time_to_failure'].values\n",
    "        for n in tqdm(range((len(data)-rows)//slide+1)):\n",
    "            x = acoustic_data[slide*n:slide*n+rows]\n",
    "            y = time_data[slide*n+rows-1]\n",
    "            \n",
    "            x = high_pass_filter(x, low_cutoff=10000, sample_rate=sample_rate)\n",
    "            x = denoise_signal(x, wavelet='haar', level=1)\n",
    "            \n",
    "            feature_series = []\n",
    "            for m in range(rows//window):\n",
    "                x_mini = x[window*m:window*(m+1)]\n",
    "                feature_series.append(feature_engineering(x_mini))\n",
    "            \n",
    "            x = np.array(pd.concat(feature_series, axis=1).values)\n",
    "    \n",
    "            if eq_num not in val_eq_nums:\n",
    "                train.append((np.array(x,'float32'),(np.array([y],'float32'))))\n",
    "            else:\n",
    "                val.append((np.array(x,'float32'),(np.array([y],'float32'))))\n",
    "        \n",
    "        if eq_num == 0:\n",
    "            break\n",
    "\n",
    "    if len(val_eq_nums) == 0:\n",
    "        return train\n",
    "\n",
    "    return train, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset_parallel(slide=150_000, window=10_000, val_eq_nums=[1,15,16]):\n",
    "    train = []\n",
    "    val = []\n",
    "\n",
    "    for eq_num in tqdm(range(17)):\n",
    "        data = pd.read_csv(DataPath/'train_wave_{}.csv'.format(eq_num))\n",
    "        acoustic_data = data['acoustic_data'].values\n",
    "        time_data = data['time_to_failure'].values\n",
    "\n",
    "        def process(n):\n",
    "            x = acoustic_data[slide*n:slide*n+rows]\n",
    "            y = time_data[slide*n+rows-1]\n",
    "            \n",
    "            x = high_pass_filter(x, low_cutoff=10000, sample_rate=sample_rate)\n",
    "            x = denoise_signal(x, wavelet='haar', level=1)\n",
    "            \n",
    "            feature_series = []\n",
    "            for m in range(rows//window):\n",
    "                x_mini = x[window*m:window*(m+1)]\n",
    "                feature_series.append(feature_engineering(x_mini))\n",
    "            \n",
    "            x = np.array(pd.concat(feature_series, axis=1).values)\n",
    "            \n",
    "            x = np.array(x,'float32')\n",
    "            y = np.array([y],'float32')\n",
    "            \n",
    "            return x, y              \n",
    "        \n",
    "        eq_data = Parallel(n_jobs=-1, verbose=5)([delayed(process)(n) for n in range((len(data)-rows)//slide+1)])\n",
    "    \n",
    "        if eq_num not in val_eq_nums:\n",
    "            train = train + eq_data\n",
    "        else:\n",
    "            val = val + eq_data\n",
    "        \n",
    "        if eq_num == 2:\n",
    "            break\n",
    "\n",
    "    if len(val_eq_nums) == 0:\n",
    "        return train\n",
    "\n",
    "    return train, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eda90ab200d44f4dbba93b5c4d2a8b6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=17), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ccfd82752b94b00bbe052a03f07dbb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=37), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train, val =  make_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, (105, 15))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), train[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d2d922a2f54663b3827b656f4ea61a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=17), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "428eaacf94ab40ac8879b37ef749ee96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=37), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  37 | elapsed:   12.3s remaining:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  37 out of  37 | elapsed:   14.0s finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a74c28ae3ede456c85246a1b1fae60f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=296), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   20.1s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   51.8s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 296 out of 296 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6506bf8bf4444c07b908a9cab7c68a9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=363), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   50.0s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 363 out of 363 | elapsed:  2.0min finished\n"
     ]
    }
   ],
   "source": [
    "train2, val2 =  make_dataset_parallel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, (105, 15))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train2), val2[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.7 (pyenv - venv367)",
   "language": "python",
   "name": "pyenv-venv367"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
